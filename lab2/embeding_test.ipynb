{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b0af3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7cd19b975170>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import emb\n",
    "import pos_emb\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca59925",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "batch_size = 2\n",
    "seq_len = 40\n",
    "\n",
    "max_seq_len = 300\n",
    "vocab_size = 100\n",
    "emb_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc850f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Token Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e035a",
   "metadata": {},
   "source": [
    "Задача: каждому токену из словаря сопоставить вектор, так чтоб семантически близкие токены были близки в в пространстве  эмбендингов\n",
    "$$[vocab\\_size \\times embeding\\_size]float$$\n",
    "кроме того если подавать закодированную последовательность в GPT напрямую, то чтоб уйти от упорядоченности в номерах кодирования, пришлось бы применять one-hot-encoding.\n",
    "Значит имели бы сильно разряженные матрицы на входе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c973f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_emb = emb.TokenEmbeddings(vocab_size,emb_size,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04eacc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 40]), torch.int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x размером (batch_size,seq_len) значения из словаря 0..vocab_size-1 \n",
    "# torch.nn.Embedding требует на входе torch.LongTensor\n",
    "x = torch.randint(low=0,high=vocab_size-1,size=(batch_size,seq_len),device=device,dtype=torch.long)\n",
    "x.shape, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbe0ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 40, 128]), torch.float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# на выходе получаем тензор (batch_size,seq_len,emb_size)\n",
    "y = token_emb.forward(x)\n",
    "y.shape, y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4fb0bd",
   "metadata": {},
   "source": [
    "# Positional Embeddings\n",
    "\n",
    "Задача: уловить закономерности в порядке слов, структуру предложения\n",
    "$$[max\\_seq\\_len \\times embeding\\_size]float$$\n",
    "$max\\_seq\\_len$ - длина контекста, максимальная длина последовательности токенов\n",
    "\n",
    "Positional Embeddings ставят в соответствие номер токена в последовательности вектору\n",
    "те разные последовательности одинаковой длины имеют одинаковые эмбендинги\n",
    "в данной работе позиционные эмбендинги обучаются (хотя в исходном варианте gpt1 они не обучались)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df08d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_emb = pos_emb.PositionalEmbeddings(max_seq_len=max_seq_len,emb_size=emb_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff30ea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 128]), torch.float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возвращает матрицу размером (seq_len,emb_size)\n",
    "p_emb = positional_emb.forward(seq_len=seq_len)\n",
    "p_emb.shape, p_emb.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mag24-nlp (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
