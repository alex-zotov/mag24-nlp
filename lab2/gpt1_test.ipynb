{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529509be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x756801b2f170>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gpt1\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8490bb",
   "metadata": {},
   "source": [
    "# GPT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43777a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "batch_size = 2\n",
    "seq_len = 40\n",
    "\n",
    "max_seq_len = 300\n",
    "vocab_size = 100\n",
    "emb_size = 128\n",
    "\n",
    "head_size = 4\n",
    "num_heads = 3\n",
    "num_layers = 5\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da23482f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 40]), torch.int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# на входе тензор токенов (batch_size,seq_len)\n",
    "x = torch.randint(low=0,high=vocab_size-1,size=(batch_size,seq_len), dtype=torch.long, device=device)\n",
    "x.shape, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596180f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = gpt1.GPT(\n",
    "    vocab_size=vocab_size,\n",
    "    max_seq_len=max_seq_len,\n",
    "    emb_size=emb_size,\n",
    "    num_heads=num_heads,\n",
    "    head_size=head_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38eb0bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 40, 100]), torch.float32, False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  на выходе loggits batch_size x seq_len x vocab_size\n",
    "y = gpt.forward(x)\n",
    "y.shape, y.dtype, torch.isnan(y).any().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e66be",
   "metadata": {},
   "source": [
    "# GPT.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe012dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 60]),\n",
       " torch.int64,\n",
       " False,\n",
       " tensor([ 0,  1,  4,  5,  6,  7,  9, 10, 11, 12, 13, 15, 18, 20, 21, 22, 23, 24,\n",
       "         25, 26, 27, 28, 31, 32, 33, 34, 35, 40, 41, 42, 43, 46, 47, 48, 49, 50,\n",
       "         52, 53, 54, 55, 57, 58, 60, 62, 63, 65, 67, 68, 69, 74, 76, 79, 80, 81,\n",
       "         82, 83, 84, 85, 89, 94, 95, 98]),\n",
       " 62)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_new_tokens = 20\n",
    "#  на выходе []int batch_size x (seq_len + max_new_tokens)\n",
    "new_seq = gpt.generate(x=x,max_new_tokens=max_new_tokens)\n",
    "new_seq.shape, new_seq.dtype, torch.isnan(new_seq).any().item(), torch.unique(new_seq), len(torch.unique(new_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4363f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 3]), torch.float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заготовка, чтоб посмотреть как работает softmax\n",
    "# batch_size x seq_len x vocab_size\n",
    "logits = torch.rand([2,4,3])\n",
    "logits.shape,logits.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec3ecbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]),\n",
       " tensor([[0.8099, 0.0461, 0.0193],\n",
       "         [0.2994, 0.9919, 0.3432]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# берём последний токен\n",
    "last_log = logits[:,-1,:]\n",
    "last_log.shape, last_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2071c218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5210, 0.2427, 0.2363],\n",
       "        [0.2473, 0.4943, 0.2584]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сумма по каждой строке 1\n",
    "# для каждого batch один следующий токен\n",
    "prob = torch.softmax(last_log,dim=-1)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b49c6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5210+ 0.2427+ 0.2363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6415739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep_dim чтоб потом можно было сделать cat c batch_size x seq_len -> batch_size x (seq_len+1)\n",
    "next_token = torch.argmax(prob,dim=-1,keepdim=True)\n",
    "next_token, next_token.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5747011",
   "metadata": {},
   "source": [
    "# GPT.generate (multinominal sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8b78b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 60]),\n",
       " torch.int64,\n",
       " False,\n",
       " tensor([ 1,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21,\n",
       "         22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 35, 40, 41, 42, 45, 46, 47, 48,\n",
       "         49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 62, 65, 67, 68, 69, 70, 72, 74,\n",
       "         75, 77, 79, 80, 81, 82, 83, 84, 85, 89, 94, 95, 98, 99]),\n",
       " 68)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# включили сэмплирование - набор токенов в ответе стал разнообразней (не только самые вероятные)\n",
    "new_seq = gpt.generate(x=x,max_new_tokens=max_new_tokens,do_sample=True)\n",
    "new_seq.shape, new_seq.dtype, torch.isnan(new_seq).any().item(), torch.unique(new_seq),len(torch.unique(new_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9fae3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5210, 0.2427, 0.2363],\n",
       "        [0.2473, 0.4943, 0.2584]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заготовка для Multinomial sampling (вероятностного сэмплирования)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12d837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [0]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# здесь с размерностью всё хорошо batch_size x 1\n",
    "next_token=torch.multinomial(prob,num_samples=1)\n",
    "next_token,next_token.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca57cb1",
   "metadata": {},
   "source": [
    "# GPT.generate (temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37758e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 60]),\n",
       " torch.int64,\n",
       " False,\n",
       " tensor([ 1,  2,  3,  4,  6,  7,  9, 10, 11, 12, 13, 15, 18, 20, 21, 22, 23, 24,\n",
       "         25, 26, 27, 28, 30, 32, 33, 35, 37, 38, 40, 41, 42, 45, 47, 48, 49, 50,\n",
       "         52, 53, 54, 55, 57, 58, 60, 62, 63, 65, 67, 68, 69, 70, 74, 76, 79, 80,\n",
       "         81, 82, 83, 84, 89, 93, 94, 95, 96, 98]),\n",
       " 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# с температурой можем получить промежуточный результат\n",
    "new_seq = gpt.generate(x=x,max_new_tokens=max_new_tokens,do_sample=True, temperature=0.3)\n",
    "new_seq.shape, new_seq.dtype, torch.isnan(new_seq).any().item(), torch.unique(new_seq), len(torch.unique(new_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331435f",
   "metadata": {},
   "source": [
    "# GPT.generate (top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2243cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 60]),\n",
       " torch.int64,\n",
       " False,\n",
       " tensor([ 1,  4,  6,  7,  9, 10, 11, 12, 13, 15, 18, 20, 21, 22, 23, 24, 25, 26,\n",
       "         27, 32, 33, 34, 35, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "         54, 55, 57, 58, 60, 62, 63, 65, 66, 67, 68, 69, 70, 73, 74, 76, 79, 80,\n",
       "         81, 82, 83, 84, 86, 89, 92, 94, 95, 98]),\n",
       " 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# не всё так однозначно - кол-во различных токенов может и нерасти растёт с ростом top_k\n",
    "new_seq = gpt.generate(x=x,max_new_tokens=max_new_tokens,do_sample=True, top_k=2)\n",
    "new_seq.shape, new_seq.dtype, torch.isnan(new_seq).any().item(), torch.unique(new_seq), len(torch.unique(new_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe9e9d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 60]),\n",
       " torch.int64,\n",
       " False,\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 17, 18, 20,\n",
       "         21, 22, 23, 24, 25, 26, 27, 32, 33, 35, 40, 41, 42, 45, 47, 48, 49, 50,\n",
       "         52, 53, 54, 55, 57, 58, 60, 62, 65, 67, 68, 69, 70, 72, 74, 78, 79, 80,\n",
       "         81, 82, 83, 84, 88, 89, 90, 93, 94, 95]),\n",
       " 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_seq = gpt.generate(x=x,max_new_tokens=max_new_tokens,do_sample=True, top_k=25)\n",
    "new_seq.shape, new_seq.dtype, torch.isnan(new_seq).any().item(), torch.unique(new_seq), len(torch.unique(new_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea3db4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " torch.float32,\n",
       " tensor([[0.2331, 0.8004, 0.7314, 0.6114, 0.2042],\n",
       "         [0.3388, 0.9878, 0.0284, 0.1518, 0.7985]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заготовка\n",
    "# batch_size x seq_len x vocab_size\n",
    "logits = torch.rand([2,4,5])\n",
    "# batch_size x vocab_size\n",
    "logits = logits[:,-1,:]\n",
    "logits.shape,logits.dtype,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b53f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [1, 4, 0]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# индексы трёх максимальных токенов\n",
    "_, top_k_ind = torch.topk(logits,k=3, dim=-1)\n",
    "top_k_ind, top_k_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e7a3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -inf, 0.2331, 0.8004, 0.7314,   -inf],\n",
       "        [0.0284, 0.3388,   -inf,   -inf, 0.9878]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = torch.full_like(logits,float('-inf'))\n",
    "filtered.scatter_(dim=-1,index=top_k_ind, src=logits)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c799e227",
   "metadata": {},
   "source": [
    "# GPT.generate (top_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adda9fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " torch.float32,\n",
       " tensor([[0.4911, 0.9985, 0.3851, 0.7970, 0.3258],\n",
       "         [0.0306, 0.9679, 0.9019, 0.9500, 0.2201]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заготовка\n",
    "# batch_size x seq_len x vocab_size\n",
    "logits = torch.rand([2,4,5])\n",
    "# batch_size x vocab_size\n",
    "logits = logits[:,-1,:]\n",
    "logits.shape,logits.dtype,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f87783bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1734, 0.2881, 0.1560, 0.2355, 0.1470],\n",
       "         [0.1035, 0.2643, 0.2474, 0.2596, 0.1251]]),\n",
       " tensor([[1, 3, 0, 2, 4],\n",
       "         [1, 3, 2, 4, 0]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = torch.softmax(logits, dim=-1)\n",
    "sorted_prob, sorted_indices = torch.sort(prob, descending=True, dim=-1)\n",
    "prob,sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e70e4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2881, 0.2355, 0.1734, 0.1560, 0.1470],\n",
       "         [0.2643, 0.2596, 0.2474, 0.1251, 0.1035]]),\n",
       " tensor([[0.2881, 0.5236, 0.6970, 0.8530, 1.0000],\n",
       "         [0.2643, 0.5239, 0.7714, 0.8965, 1.0000]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob = torch.cumsum(sorted_prob, dim=-1)\n",
    "sorted_prob,cumulative_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mag24-nlp (3.8.20)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
